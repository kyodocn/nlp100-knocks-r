[["index.html", "Rで言語処理100本ノックを解くわけがない Chapter 1 はじめに 1.1 本書について 1.2 全体の見通し 1.3 使用する環境など 1.4 資料", " Rで言語処理100本ノックを解くわけがない Kato Akiru 2021-02-16 Chapter 1 はじめに 1.1 本書について Rで言語処理100本ノック 2020に取り組んでいます。 Rでやっているコードの例を示すにとどまるもので、丁寧な解説を添えているようなものではありません。中盤以降もできそうなのでやろうとは思っていますが、実際にやる見通しは立てていません。 1.2 全体の見通し 2020年版に触ってみますが、ぜんぶは解きません。無理です。 言語処理100本ノック 2020 ググって出てくる範囲では2015年版にはyamano357さんが取り組んでいます。RcppでMeCabとCaboChaのバインディングを自分で書いて解いている本格派です。 Rによる言語処理100本ノック前半まとめ - バイアスと戯れる Rによる言語処理100本ノック後半まとめと全体での総括 - バイアスと戯れる 2020年版もやろうとしている人がいるようです。 言語処理100本ノック R - Qiita 2020年版も7章の単語ベクトルあたりまではPure Rでいけそうですが、おそらく8章のディープ・ニューラルネットあたりからバックエンドにPythonを利用することになり、10章の最終題の翻訳デモの構築でふつうにPythonを利用しなければならなくなるはずなので詰みます。 1.3 使用する環境など 本書はWindows10 (64bit) でチャンクを実行してビルドしています。 1.3.1 MeCab/CaboCha MeCab (0.996) CaboCha (0.69) 1.4 資料 参考としてRで形態素解析するパッケージの速度比較をします。 以下を試しています。 RMeCab::RMeCabC RcppMeCab::pos RcppMeCab::posParallel rjavacmecab::cmecab RcppKagome::kagome tangela::kuromoji RcppMeCab::posはMeCabのタガーインスタンスを一つだけつくってそれぞれの文をひとつずつ解析する処理を繰り返します。一方で、RcppMeCab::posParallelはマルチスレッドで、スレッドごとにMeCabのタガーインスタンスを生成します。形態素解析をするライブラリでは一般にタガーインスタンスの生成はコストが高い処理であるため、スレッドごとに処理する文の分量が極端に少ない場合、解析にかかる時間の割にインスタンスの生成にコストが割かれることになって、RcppMeCab::posParallelではパフォーマンスが悪化することがあります。 以下は解析する文書のサンプル。 csv &lt;- file.path(&quot;miyazawa_kenji_head.csv&quot;) %&gt;% readr::read_csv() %&gt;% dplyr::sample_n(50L) %&gt;% dplyr::mutate( sentences_shift_jis = iconv(sentences, from = &quot;UTF-8&quot;, to = &quot;CP932&quot;) ) #&gt; #&gt; -- Column specification -------------------------------------------------------------------------- #&gt; cols( #&gt; rowid = col_double(), #&gt; sentences = col_character() #&gt; ) dplyr::glimpse(csv) #&gt; Rows: 50 #&gt; Columns: 3 #&gt; $ rowid &lt;dbl&gt; 347, 855, 214, 482, 175, 721, 505, 438, 398, 273, 619, 269, 351, ... #&gt; $ sentences &lt;chr&gt; &quot;そしていつか薄明は黄昏に入りかわられ、苔の花も赤ぐろく見え西の山稜の上のそらばかりかすかに黄いろに濁りました。&quot;, &quot;赤衣の童子... #&gt; $ sentences_shift_jis &lt;chr&gt; &quot;そしていつか薄明は黄昏に入りかわられ、苔の花も赤ぐろく見え西の山稜の上のそらばかりかすかに黄いろに濁りました。&quot;, &quot;赤衣の童子... 1.4.0.1 Tokenize Character Scalar ひとつの文について繰り返し解析する場合。 tm &lt;- microbenchmark::microbenchmark( RMeCabC = RMeCabC(csv$sentences_shift_jis[1], mecabrc = &quot;/MeCab/ipadic-shiftjis/mecabrc&quot;), pos = pos(csv$sentences[1]), posParallel = posParallel(csv$sentences[1]), cmecab = cmecab(csv$sentences[1]), kagome = kagome(csv$sentences[1]), kuromoji = kuromoji(csv$sentences[1]), times = 50L ) summary(tm) #&gt; expr min lq mean median uq max neval #&gt; 1 RMeCabC 3.0155 3.2385 20.619522 3.38500 3.5665 862.3091 50 #&gt; 2 pos 2.9884 3.2722 3.388008 3.36245 3.4773 4.6014 50 #&gt; 3 posParallel 2.9872 3.2546 3.394910 3.33370 3.4874 4.1703 50 #&gt; 4 cmecab 9.6907 10.4392 16.617694 10.67050 11.9419 276.5225 50 #&gt; 5 kagome 2.4749 2.7383 2.915894 2.81345 2.9617 5.8504 50 #&gt; 6 kuromoji 217.2163 225.9560 246.229476 244.68695 261.6305 304.3357 50 ggplot2::autoplot(tm) #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. 1.4.1 Tokenize Character Vector 50文を長さ50のベクトルとして与える場合。 RMeCab::RMeCabCとtangela::kuromojiは長さが1のベクトル（character scalar）しか受けつけないため、ここではsapplyでラップしています。なお、rjavacmecab::cmecabについては、ベクトルを与えられた場合は要素を改行でcollapseしてひとつの文にして解析するため、他とは挙動が異なります。 tm &lt;- microbenchmark::microbenchmark( RMeCabC = purrr::map(csv$sentences_shift_jis, ~ RMeCabC(., mecabrc = &quot;/MeCab/ipadic-shiftjis/mecabrc&quot;)), pos = pos(csv$sentences), posParallel = posParallel(csv$sentences), cmecab = cmecab(csv$sentences), kagome = kagome(csv$sentences), kuromoji = sapply(csv$sentences, kuromoji), times = 5L ) summary(tm) #&gt; expr min lq mean median uq max neval #&gt; 1 RMeCabC 150.4584 153.3500 1270.22864 178.0550 181.2502 5688.0296 5 #&gt; 2 pos 17.2667 17.6529 18.30192 17.8548 18.3914 20.3438 5 #&gt; 3 posParallel 11.8519 12.5680 613.95158 12.7139 13.3224 3019.3017 5 #&gt; 4 cmecab 19.2414 20.6727 24.93838 22.7050 27.7548 34.3180 5 #&gt; 5 kagome 150.9533 156.9502 178.91226 172.3360 183.6851 230.6367 5 #&gt; 6 kuromoji 14988.8617 15124.3121 15323.30820 15169.1730 15581.3309 15752.8633 5 ggplot2::autoplot(tm) #&gt; Coordinate system already present. Adding new coordinate system, which will replace the existing one. "],["準備運動unixコマンド正規表現.html", "Chapter 2 準備運動・UNIXコマンド・正規表現 2.1 準備運動 2.2 UNIXコマンド 2.3 正規表現", " Chapter 2 準備運動・UNIXコマンド・正規表現 2.1 準備運動 コーディングの方針として、値はなるべくリストのまま持っておいて最後にunlistする感じにしています。また、pasteではなくてstringr::str_cで統一しています。 2.1.1 00. 文字列の逆順 stringr::str_split(&quot;stressed&quot;, pattern = &quot;&quot;) %&gt;% purrr::map(~ rev(.)) %&gt;% unlist() %&gt;% stringr::str_c(collapse = &quot;&quot;) #&gt; [1] &quot;desserts&quot; 2.1.2 01. 「パタトクカシーー」 stringr::str_split(&quot;パタトクカシーー&quot;, pattern = &quot;&quot;) %&gt;% purrr::map(~ purrr::pluck(.[c(TRUE, FALSE)])) %&gt;% unlist() %&gt;% stringr::str_c(collapse = &quot;&quot;) #&gt; [1] &quot;パトカー&quot; 2.1.3 02. 「パトカー」「タクシー」「パタトクカシーー」 list(&quot;パトカー&quot;, &quot;タクシー&quot;) %&gt;% purrr::map(~ stringr::str_split(., pattern = &quot;&quot;)) %&gt;% purrr::flatten() %&gt;% purrr::pmap(~ stringr::str_c(.x, .y, collapse = &quot;&quot;)) %&gt;% unlist() %&gt;% stringr::str_c(collapse = &quot;&quot;) #&gt; [1] &quot;パタトクカシーー&quot; 2.1.4 03. 円周率 stringr::str_split(&quot;Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.&quot;, pattern = &quot; &quot;) %&gt;% purrr::flatten() %&gt;% purrr::map(~ stringr::str_count(., pattern = &quot;[:alpha:]&quot;)) %&gt;% unlist() #&gt; [1] 3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 2.1.5 04. 元素記号 stringr::str_split(&quot;Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.&quot;, pattern = &quot; &quot;) %&gt;% purrr::flatten() %&gt;% purrr::imap(~ dplyr::if_else( .y %in% c(1, 5, 6, 7, 8, 9, 15, 16, 19), stringr::str_sub(.x, 1, 1), stringr::str_sub(.x, 1, 2) )) %&gt;% purrr::imap(function(x, i) { names(x) &lt;- i return(x) }) %&gt;% unlist() #&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #&gt; &quot;H&quot; &quot;He&quot; &quot;Li&quot; &quot;Be&quot; &quot;B&quot; &quot;C&quot; &quot;N&quot; &quot;O&quot; &quot;F&quot; &quot;Ne&quot; &quot;Na&quot; &quot;Mi&quot; &quot;Al&quot; &quot;Si&quot; &quot;P&quot; &quot;S&quot; &quot;Cl&quot; &quot;Ar&quot; &quot;K&quot; #&gt; 20 #&gt; &quot;Ca&quot; 2.1.6 05. n-gram ngram &lt;- function(x, n = 2, sep = &quot; &quot;) { stopifnot(is.character(x)) #### 先例がみんな`embed`を使っているが、ここでは使わない #### tokens &lt;- unlist(stringr::str_split(x, pattern = sep)) len &lt;- length(tokens) if (len &lt; n) { res &lt;- character(0) } else { res &lt;- sapply(1:max(1, len - n + 1), function(i) { stringr::str_c(tokens[i:min(len, i + n - 1)], collapse = &quot; &quot;) }) } return(res) } ngram(&quot;I am an NLPer&quot;) #&gt; [1] &quot;I am&quot; &quot;am an&quot; &quot;an NLPer&quot; 2.1.7 06. 集合 回答略 2.1.8 07. テンプレートによる文生成 回答略 2.1.9 08. 暗号文 cipher &lt;- function(str) { f &lt;- purrr::as_mapper(~ 219 - .) v &lt;- stringr::str_split(str, pattern = &quot;&quot;, simplify = TRUE) res &lt;- sapply(v[1, ], function(char) { dplyr::if_else( stringr::str_detect(char, &quot;[:lower:]&quot;), char %&gt;% charToRaw() %&gt;% as.integer() %&gt;% f() %&gt;% as.raw() %&gt;% rawToChar(), char ) }) return(stringr::str_c(res, collapse = &quot;&quot;)) } cipher(&quot;I couldn&#39;t believe that I could actually understand what I was reading : the phenomenal power of the human mind.&quot;) #&gt; [1] &quot;I xlfowm&#39;g yvorvev gszg I xlfow zxgfzoob fmwvihgzmw dszg I dzh ivzwrmt : gsv ksvmlnvmzo kldvi lu gsv sfnzm nrmw.&quot; 2.1.10 09. Typoglycemia typoglycemia &lt;- function(str) { f &lt;- function(char) { subset &lt;- stringr::str_sub(char, 2, nchar(char) - 1) %&gt;% stringr::str_split(pattern = &quot;&quot;) %&gt;% purrr::flatten() %&gt;% sample() res &lt;- stringr::str_c( c( stringr::str_sub(char, 1, 1), subset, stringr::str_sub(char, nchar(char), nchar(char)) ), collapse = &quot;&quot; ) return(res) } res &lt;- stringr::str_split(str, pattern = &quot; &quot;) %&gt;% purrr::flatten() %&gt;% purrr::map(~ dplyr::if_else( nchar(stringr::str_subset(., &quot;[:alpha:]|:&quot;)) &lt;= 4, ., f(.) )) return(stringr::str_c(res, collapse = &quot; &quot;)) } typoglycemia(&quot;I couldn&#39;t believe that I could actually understand what I was reading : the phenomenal power of the human mind.&quot;) #&gt; [1] &quot;I cu&#39;dlnot bevelie that I cluod aulcatly udsetnanrd what I was reinadg : the peeomhannl pweor of the huamn mdni.&quot; 2.2 UNIXコマンド 確認はやりません。だってWindowsだもん 2.2.1 10~15 素のテキストとして読んでもしょうがないので、以下のようなこと雰囲気でやります。 行数のカウント タブをスペースに置換 先頭からN行を出力 末尾のN行を出力 以下の２つはやりませんが、たぶんfread(temp, select = c(1, 2))みたいな感じで取れます。 1列目をcol1.txtに，2列目をcol2.txtに保存 col1.txtとcol2.txtをマージ knitr::clean_cache(TRUE) #&gt; NULL temp &lt;- tempfile(fileext = &quot;.txt&quot;) download.file(&quot;https://nlp100.github.io/data/popular-names.txt&quot;, temp) txt &lt;- temp %&gt;% data.table::fread( sep = &quot;\\t&quot;, quote = &quot;&quot;, header = FALSE, col.names = c(&quot;name&quot;, &quot;sex&quot;, &quot;num_of_people&quot;, &quot;year&quot;), colClasses = list(&quot;character&quot; = 1, &quot;character&quot; = 2, &quot;integer&quot; = 3, &quot;integer&quot; = 4), data.table = FALSE ) nrow(txt) #&gt; [1] 2780 head(txt, 3) #&gt; name sex num_of_people year #&gt; 1 Mary F 7065 1880 #&gt; 2 Anna F 2604 1880 #&gt; 3 Emma F 2003 1880 tail(txt, 3) #&gt; name sex num_of_people year #&gt; 2778 Lucas M 12585 2018 #&gt; 2779 Mason M 12435 2018 #&gt; 2780 Logan M 12352 2018 2.2.2 16. ファイルをN分割する split(txt, sort(rank(row.names(txt)) %% 5)) %&gt;% purrr::map(~ head(.)) %&gt;% print() #&gt; $`0` #&gt; name sex num_of_people year #&gt; 1 Mary F 7065 1880 #&gt; 2 Anna F 2604 1880 #&gt; 3 Emma F 2003 1880 #&gt; 4 Elizabeth F 1939 1880 #&gt; 5 Minnie F 1746 1880 #&gt; 6 Margaret F 1578 1880 #&gt; #&gt; $`1` #&gt; name sex num_of_people year #&gt; 557 Joseph M 3844 1907 #&gt; 558 Frank M 2943 1907 #&gt; 559 Edward M 2576 1907 #&gt; 560 Henry M 2203 1907 #&gt; 561 Mary F 18665 1908 #&gt; 562 Helen F 8439 1908 #&gt; #&gt; $`2` #&gt; name sex num_of_people year #&gt; 1113 John M 47499 1935 #&gt; 1114 William M 40198 1935 #&gt; 1115 Richard M 33945 1935 #&gt; 1116 Charles M 29983 1935 #&gt; 1117 Donald M 29661 1935 #&gt; 1118 George M 18559 1935 #&gt; #&gt; $`3` #&gt; name sex num_of_people year #&gt; 1669 Sandra F 21619 1963 #&gt; 1670 Cynthia F 21593 1963 #&gt; 1671 Michael M 83782 1963 #&gt; 1672 John M 78625 1963 #&gt; 1673 David M 78467 1963 #&gt; 1674 James M 71322 1963 #&gt; #&gt; $`4` #&gt; name sex num_of_people year #&gt; 2225 Samantha F 25645 1991 #&gt; 2226 Sarah F 25225 1991 #&gt; 2227 Stephanie F 22774 1991 #&gt; 2228 Jennifer F 20673 1991 #&gt; 2229 Elizabeth F 20392 1991 #&gt; 2230 Emily F 20308 1991 2.2.3 17. １列目の文字列の異なり 省略 2.2.4 18. 各行を3コラム目の数値の降順にソート txt %&gt;% dplyr::arrange(desc(num_of_people)) %&gt;% head() #&gt; name sex num_of_people year #&gt; 1 Linda F 99689 1947 #&gt; 2 Linda F 96211 1948 #&gt; 3 James M 94757 1947 #&gt; 4 Michael M 92704 1957 #&gt; 5 Robert M 91640 1947 #&gt; 6 Linda F 91016 1949 2.2.5 19. 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる purrr::map_dfr(txt$name, function(name) { stringr::str_split(name, pattern = &quot;&quot;, simplify = TRUE) %&gt;% t() %&gt;% as.data.frame(stringsAsFactors = FALSE) }) %&gt;% dplyr::rename(string = V1) %&gt;% dplyr::group_by(string) %&gt;% dplyr::count(string, sort = TRUE) %&gt;% head() #&gt; # A tibble: 6 x 2 #&gt; # Groups: string [6] #&gt; string n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 a 2194 #&gt; 2 e 1554 #&gt; 3 r 1270 #&gt; 4 i 1183 #&gt; 5 h 1018 #&gt; 6 l 943 2.3 正規表現 自然言語処理とはいったい 2.3.1 20. JSONデータの読み込み knitr::clean_cache() #&gt; NULL temp &lt;- tempfile(fileext = &quot;.gz&quot;) download.file(&quot;https://nlp100.github.io/data/jawiki-country.json.gz&quot;, temp) con &lt;- gzfile(description = temp, open = &quot;rb&quot;) jsonfile &lt;- readr::read_lines(con, locale = readr::locale(encoding = &quot;UTF-8&quot;)) %&gt;% purrr::map_dfr(~ jsonlite::fromJSON(.)) close(con) jsonfile %&gt;% dplyr::filter(title == &quot;イギリス&quot;) %&gt;% dplyr::pull(text) %&gt;% dplyr::glimpse() ## 長いので #&gt; chr &quot;{{redirect|UK}}\\n{{redirect|英国|春秋時代の諸侯国|英 (春秋)}}\\n{{Otheruses|ヨーロッパの国|長崎県・熊本県の郷土&quot;| __truncated__ 2.3.2 21. カテゴリ名を含む行を抽出 lines &lt;- jsonfile %&gt;% dplyr::filter(title == &quot;イギリス&quot;) %&gt;% dplyr::pull(text) %&gt;% readr::read_lines() %&gt;% stringr::str_subset(stringr::fixed(&quot;[[Category:&quot;)) lines #&gt; [1] &quot;[[Category:イギリス|*]]&quot; &quot;[[Category:イギリス連邦加盟国]]&quot; #&gt; [3] &quot;[[Category:英連邦王国|*]]&quot; &quot;[[Category:G8加盟国]]&quot; #&gt; [5] &quot;[[Category:欧州連合加盟国|元]]&quot; &quot;[[Category:海洋国家]]&quot; #&gt; [7] &quot;[[Category:現存する君主国]]&quot; &quot;[[Category:島国]]&quot; #&gt; [9] &quot;[[Category:1801年に成立した国家・領域]]&quot; 以下、回答略 "],["形態素解析.html", "Chapter 3 形態素解析 3.1 データの読み込み 3.2 形態素解析", " Chapter 3 形態素解析 3.1 データの読み込み readtextで読みこんでおきます。 temp &lt;- tempfile(fileext = &quot;.txt&quot;) download.file(&quot;https://nlp100.github.io/data/neko.txt&quot;, temp) neko &lt;- readtext::readtext(temp, encoding = &quot;UTF-8&quot;) neko$text[1] %&gt;% readr::read_lines(skip_empty_rows = TRUE) %&gt;% length() #&gt; [1] 9210 3.2 形態素解析 3.2.1 30. 形態素解析結果の読み込み RMeCabは必要な情報を取りづらいので、paithiov909/RcppKagomeを使います。RcppMeCabでもできますが、公式のリポジトリのソースはWindows環境だとビルドにコケるのでUNIX系の環境が必要です（2021年1月現在）。 すべて解析すると時間がかかるのでここでは一部だけ使います。 neko_txt_mecab &lt;- neko %&gt;% dplyr::slice(1:1000) %&gt;% dplyr::pull(&quot;text&quot;) %&gt;% RcppKagome::kagome() %&gt;% RcppKagome::prettify() head(neko_txt_mecab) #&gt; sentence_id token POS1 POS2 POS3 POS4 X5StageUse1 X5StageUse2 Original Yomi1 Yomi2 #&gt; 1 1 一 名詞 数 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 一 イチ イチ #&gt; 2 1 \\n\\n 記号 空白 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; #&gt; 3 1 記号 空白 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; #&gt; 4 1 吾輩 名詞 代名詞 一般 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 吾輩 ワガハイ ワガハイ #&gt; 5 1 は 助詞 係助詞 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; は ハ ワ #&gt; 6 1 猫 名詞 一般 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 猫 ネコ ネコ 3.2.2 31. 動詞 neko_txt_mecab %&gt;% dplyr::filter(POS1 == &quot;動詞&quot;) %&gt;% dplyr::select(token) %&gt;% head() #&gt; token #&gt; 1 生れ #&gt; 2 つか #&gt; 3 し #&gt; 4 泣い #&gt; 5 し #&gt; 6 いる 3.2.3 32. 動詞の原形 neko_txt_mecab %&gt;% dplyr::filter(POS1 == &quot;動詞&quot;) %&gt;% dplyr::select(Original) %&gt;% head() #&gt; Original #&gt; 1 生れる #&gt; 2 つく #&gt; 3 する #&gt; 4 泣く #&gt; 5 する #&gt; 6 いる 3.2.4 33. 「AのB」 neko_txt_mecab %&gt;% tibble::rowid_to_column() %&gt;% dplyr::filter(token == &quot;の&quot;) %&gt;% dplyr::pull(rowid) %&gt;% purrr::keep(~ neko_txt_mecab$POS1[. - 1] == &quot;名詞&quot; &amp;&amp; neko_txt_mecab$POS1[. + 1] == &quot;名詞&quot;) %&gt;% purrr::map_chr(~ stringr::str_c( neko_txt_mecab$token[. - 1], neko_txt_mecab$token[.], neko_txt_mecab$token[. + 1], collapse = &quot;&quot; )) %&gt;% head(30L) #&gt; [1] &quot;彼の掌&quot; &quot;掌の上&quot; &quot;書生の顔&quot; &quot;はずの顔&quot; &quot;顔の真中&quot; &quot;穴の中&quot; &quot;書生の掌&quot; #&gt; [8] &quot;掌の裏&quot; &quot;何の事&quot; &quot;肝心の母親&quot; &quot;藁の上&quot; &quot;笹原の中&quot; &quot;池の前&quot; &quot;池の上&quot; #&gt; [15] &quot;一樹の蔭&quot; &quot;垣根の穴&quot; &quot;隣家の三&quot; &quot;時の通路&quot; &quot;一刻の猶予&quot; &quot;家の内&quot; &quot;彼の書生&quot; #&gt; [22] &quot;以外の人間&quot; &quot;前の書生&quot; &quot;おさんの隙&quot; &quot;おさんの三&quot; &quot;胸の痞&quot; &quot;家の主人&quot; &quot;主人の方&quot; #&gt; [29] &quot;鼻の下&quot; &quot;吾輩の顔&quot; 3.2.5 34. 名詞の連接 これよくわからない。探索する処理が重いのでdplyr::sample_fracでサンプルを減らしています。 idx &lt;- neko_txt_mecab %&gt;% tibble::rowid_to_column() %&gt;% dplyr::filter(POS1 == &quot;名詞&quot;) %&gt;% dplyr::sample_frac(0.1) %&gt;% dplyr::pull(rowid) %&gt;% purrr::discard(~ neko_txt_mecab$POS1[. + 1] != &quot;名詞&quot;) search_in &lt;- idx purrr::map_chr(search_in, function(idx) { itr &lt;- idx res &lt;- stringr::str_c(neko_txt_mecab$token[idx]) while (neko_txt_mecab$POS1[itr + 1] == &quot;名詞&quot;) { res &lt;- stringr::str_c(res, neko_txt_mecab$token[itr + 1]) search_in &lt;&lt;- purrr::discard(search_in, ~ . == itr + 1) itr &lt;- itr + 1 next } return(res) }) %&gt;% head(30L) #&gt; [1] &quot;何ん&quot; &quot;先生例&quot; &quot;人当時有名&quot; &quot;下候&quot; &quot;十文半&quot; #&gt; [6] &quot;物たる&quot; &quot;袂時計&quot; &quot;南向き&quot; &quot;豚的幸福&quot; &quot;五六寸&quot; #&gt; [11] &quot;顔付&quot; &quot;伯父さん&quot; &quot;両人共応対振り&quot; &quot;伯父さん&quot; &quot;まま畳&quot; #&gt; [16] &quot;上候&quot; &quot;理想的&quot; &quot;直径一寸&quot; &quot;艶書&quot; &quot;向側&quot; #&gt; [21] &quot;三行&quot; &quot;団栗博士&quot; &quot;誰の&quot; &quot;迷亭&quot; &quot;甘木先生&quot; #&gt; [26] &quot;二本&quot; &quot;寒月君&quot; &quot;――主人&quot; &quot;猫又殿&quot; &quot;一波瀾&quot; 3.2.6 35. 単語の出現頻度 neko_txt_mecab %&gt;% dplyr::group_by(Original) %&gt;% dplyr::count(Original, sort = TRUE) %&gt;% head() #&gt; # A tibble: 6 x 2 #&gt; # Groups: Original [6] #&gt; Original n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 &lt;NA&gt; 11450 #&gt; 2 の 9194 #&gt; 3 。 7486 #&gt; 4 て 6848 #&gt; 5 、 6773 #&gt; 6 は 6421 3.2.7 36. 頻度上位10語 neko_txt_mecab %&gt;% dplyr::group_by(Original) %&gt;% dplyr::count(Original, sort = TRUE) %&gt;% head(10) %&gt;% ggplot(aes(x = reorder(Original, -n), y = n)) + geom_col() + labs(x = &quot;token form&quot;) + theme_light() 3.2.8 37. 「猫」と共起頻度の高い上位10語 解釈のしかたが複数あるけれど、ここではbi-gramを数えてお茶をにごします。 neko_txt_mecab %&gt;% tibble::rowid_to_column() %&gt;% dplyr::filter(token == &quot;猫&quot;) %&gt;% dplyr::mutate(Collocation = stringr::str_c(token, neko_txt_mecab$token[rowid + 1], sep = &quot; - &quot;)) %&gt;% dplyr::group_by(sentence_id, Collocation) %&gt;% dplyr::count(Collocation, sort = TRUE) %&gt;% head(10L) %&gt;% ggplot2::ggplot(aes(x = reorder(Collocation, -n), y = n)) + ggplot2::geom_col() + ggplot2::labs(x = &quot;Collocation&quot;, y = &quot;Freq&quot;) + ggplot2::theme_light() 3.2.9 38. ヒストグラム neko_txt_mecab %&gt;% dplyr::group_by(Original) %&gt;% dplyr::count(Original) %&gt;% ggplot2::ggplot(aes(x = reorder(Original, -n), y = n)) + ggplot2::geom_col() + ggplot2::labs(x = &quot;&quot;, y = &quot;Freq&quot;) + ggplot2::scale_y_log10() + ggplot2::theme_light() 3.2.10 39. Zipfの法則 count &lt;- neko_txt_mecab %&gt;% dplyr::group_by(Original) %&gt;% dplyr::count(Original) %&gt;% dplyr::ungroup() count %&gt;% tibble::rowid_to_column() %&gt;% dplyr::mutate(rank = nrow(count) + 1 - dplyr::min_rank(count$n)[rowid]) %&gt;% ggplot2::ggplot(aes(x = rank, y = n)) + ggplot2::geom_point() + ggplot2::labs(x = &quot;Rank of Freq&quot;, y = &quot;Freq&quot;) + ggplot2::scale_x_log10() + ggplot2::scale_y_log10() + ggplot2::theme_light() "],["セッション情報.html", "Chapter 4 セッション情報", " Chapter 4 セッション情報 sessioninfo::session_info() #&gt; - Session info --------------------------------------------------------------------------------- #&gt; setting value #&gt; version R version 4.0.2 (2020-06-22) #&gt; os Windows 10 x64 #&gt; system x86_64, mingw32 #&gt; ui RStudio #&gt; language (EN) #&gt; collate Japanese_Japan.932 #&gt; ctype Japanese_Japan.932 #&gt; tz Asia/Tokyo #&gt; date 2021-02-16 #&gt; #&gt; - Packages ------------------------------------------------------------------------------------- #&gt; ! package * version date lib source #&gt; P assertthat 0.2.1 2019-03-21 [?] CRAN (R 4.0.2) #&gt; P backports 1.2.1 2020-12-09 [?] CRAN (R 4.0.3) #&gt; P bookdown 0.21 2020-10-13 [?] CRAN (R 4.0.3) #&gt; P broom * 0.7.4 2021-01-29 [?] CRAN (R 4.0.2) #&gt; P class 7.3-17 2020-04-26 [?] CRAN (R 4.0.2) #&gt; P cli 2.3.0 2021-01-31 [?] CRAN (R 4.0.2) #&gt; P codetools 0.2-16 2018-12-24 [?] CRAN (R 4.0.2) #&gt; P colorspace 2.0-0 2020-11-11 [?] CRAN (R 4.0.3) #&gt; crayon 1.4.1 2021-02-08 [1] CRAN (R 4.0.2) #&gt; P data.table 1.13.6 2020-12-30 [?] CRAN (R 4.0.3) #&gt; P dials * 0.0.9 2020-09-16 [?] CRAN (R 4.0.2) #&gt; P DiceDesign 1.9 2021-02-13 [?] CRAN (R 4.0.2) #&gt; P digest 0.6.27 2020-10-24 [?] CRAN (R 4.0.3) #&gt; P dplyr * 1.0.4 2021-02-02 [?] CRAN (R 4.0.3) #&gt; P ellipsis 0.3.1 2020-05-15 [?] CRAN (R 4.0.2) #&gt; P evaluate 0.14 2019-05-28 [?] CRAN (R 4.0.2) #&gt; P fansi 0.4.2 2021-01-15 [?] CRAN (R 4.0.3) #&gt; P farver 2.0.3 2020-01-16 [?] CRAN (R 4.0.2) #&gt; flatxml 0.1.1 2020-12-01 [1] CRAN (R 4.0.3) #&gt; P foreach 1.5.1 2020-10-15 [?] CRAN (R 4.0.3) #&gt; furrr 0.2.2 2021-01-29 [1] CRAN (R 4.0.3) #&gt; future 1.21.0 2020-12-10 [1] CRAN (R 4.0.3) #&gt; generics 0.1.0 2020-10-31 [1] CRAN (R 4.0.3) #&gt; P ggplot2 * 3.3.3 2020-12-30 [?] CRAN (R 4.0.3) #&gt; globals 0.14.0 2020-11-22 [1] CRAN (R 4.0.3) #&gt; P glue 1.4.2 2020-08-27 [?] CRAN (R 4.0.2) #&gt; P gower 0.2.2 2020-06-23 [?] CRAN (R 4.0.2) #&gt; P GPfit 1.0-8 2019-02-08 [?] CRAN (R 4.0.2) #&gt; P gtable 0.3.0 2019-03-25 [?] CRAN (R 4.0.2) #&gt; P highr 0.8 2019-03-20 [?] CRAN (R 4.0.2) #&gt; hms 1.0.0 2021-01-13 [1] CRAN (R 4.0.3) #&gt; P htmltools 0.5.1.1 2021-01-22 [?] CRAN (R 4.0.3) #&gt; P httr 1.4.2 2020-07-20 [?] CRAN (R 4.0.2) #&gt; igraph 1.2.6 2020-10-06 [1] CRAN (R 4.0.3) #&gt; P infer * 0.5.4 2021-01-13 [?] CRAN (R 4.0.3) #&gt; P ipred 0.9-9 2019-04-28 [?] CRAN (R 4.0.2) #&gt; P iterators 1.0.13 2020-10-15 [?] CRAN (R 4.0.3) #&gt; P jsonlite 1.7.2 2020-12-09 [?] CRAN (R 4.0.3) #&gt; P knitr 1.31 2021-01-27 [?] CRAN (R 4.0.3) #&gt; P labeling 0.4.2 2020-10-20 [?] CRAN (R 4.0.3) #&gt; P lattice 0.20-41 2020-04-02 [?] CRAN (R 4.0.2) #&gt; P lava 1.6.8.1 2020-11-04 [?] CRAN (R 4.0.3) #&gt; P lhs 1.1.1 2020-10-05 [?] CRAN (R 4.0.3) #&gt; lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.0.2) #&gt; listenv 0.8.0 2019-12-05 [1] CRAN (R 4.0.3) #&gt; P lubridate 1.7.9.2 2020-11-13 [?] CRAN (R 4.0.3) #&gt; P magrittr 2.0.1 2020-11-17 [?] CRAN (R 4.0.3) #&gt; P MASS 7.3-51.6 2020-04-26 [?] CRAN (R 4.0.2) #&gt; P Matrix 1.2-18 2019-11-27 [?] CRAN (R 4.0.2) #&gt; P microbenchmark 1.4-7 2019-09-24 [?] CRAN (R 4.0.2) #&gt; P modeldata * 0.1.0 2020-10-22 [?] CRAN (R 4.0.3) #&gt; P munsell 0.5.0 2018-06-12 [?] CRAN (R 4.0.2) #&gt; P nnet 7.3-14 2020-04-26 [?] CRAN (R 4.0.2) #&gt; parallelly 1.23.0 2021-01-04 [1] CRAN (R 4.0.3) #&gt; P parsnip * 0.1.5 2021-01-19 [?] CRAN (R 4.0.3) #&gt; P pillar 1.4.7 2020-11-20 [?] CRAN (R 4.0.3) #&gt; pipian * 0.2.4 2021-02-15 [1] Github (paithiov909/pipian@9cf7bc2) #&gt; P pkgconfig 2.0.3 2019-09-22 [?] CRAN (R 4.0.2) #&gt; P plyr 1.8.6 2020-03-03 [?] CRAN (R 4.0.2) #&gt; P pROC 1.17.0.1 2021-01-13 [?] CRAN (R 4.0.3) #&gt; P prodlim 2019.11.13 2019-11-17 [?] CRAN (R 4.0.2) #&gt; P purrr * 0.3.4 2020-04-17 [?] CRAN (R 4.0.2) #&gt; P R.cache 0.14.0 2019-12-06 [?] CRAN (R 4.0.2) #&gt; P R.methodsS3 1.8.1 2020-08-26 [?] CRAN (R 4.0.2) #&gt; P R.oo 1.24.0 2020-08-26 [?] CRAN (R 4.0.2) #&gt; P R.utils 2.10.1 2020-08-26 [?] CRAN (R 4.0.2) #&gt; P R6 2.5.0 2020-10-28 [?] CRAN (R 4.0.3) #&gt; P Rcpp 1.0.6 2021-01-15 [?] CRAN (R 4.0.3) #&gt; RcppKagome * 0.0.0.600 2021-02-15 [1] Github (paithiov909/RcppKagome@2a2b9d0) #&gt; RcppMeCab * 0.0.1.3-2 2021-02-15 [1] Github (junhewk/RcppMeCab@e1800aa) #&gt; D RcppParallel 5.0.2 2020-06-24 [1] CRAN (R 4.0.3) #&gt; readr 1.4.0 2020-10-05 [1] CRAN (R 4.0.3) #&gt; P readtext 0.80 2020-09-22 [?] CRAN (R 4.0.2) #&gt; P recipes * 0.1.15 2020-11-11 [?] CRAN (R 4.0.3) #&gt; renv 0.12.5 2021-01-09 [1] CRAN (R 4.0.3) #&gt; D rJava 0.9-13 2020-07-06 [1] CRAN (R 4.0.3) #&gt; rjavacmecab * 0.2.1 2021-02-15 [1] Github (paithiov909/rjavacmecab@d2002c9) #&gt; P rlang 0.4.10 2020-12-30 [?] CRAN (R 4.0.3) #&gt; P rmarkdown 2.6 2020-12-14 [?] CRAN (R 4.0.3) #&gt; RMeCab * 1.05 2020-04-28 [1] local #&gt; P rpart 4.1-15 2019-04-12 [?] CRAN (R 4.0.2) #&gt; P rsample * 0.0.8 2020-09-23 [?] CRAN (R 4.0.2) #&gt; P rstudioapi 0.13 2020-11-12 [?] CRAN (R 4.0.3) #&gt; rvest 0.3.6 2020-07-25 [1] CRAN (R 4.0.3) #&gt; P scales * 1.1.1 2020-05-11 [?] CRAN (R 4.0.2) #&gt; P sessioninfo 1.1.1 2018-11-05 [?] CRAN (R 4.0.2) #&gt; P stringi 1.5.3 2020-09-09 [?] CRAN (R 4.0.2) #&gt; P stringr 1.4.0 2019-02-10 [?] CRAN (R 4.0.2) #&gt; P styler 1.3.2 2020-02-23 [?] CRAN (R 4.0.2) #&gt; P survival 3.1-12 2020-04-10 [?] CRAN (R 4.0.2) #&gt; tangela * 0.0.4-4 2021-02-15 [1] Github (paithiov909/tangela@538638e) #&gt; P textrecipes * 0.4.0 2020-11-12 [?] CRAN (R 4.0.3) #&gt; P tibble * 3.0.6 2021-01-29 [?] CRAN (R 4.0.3) #&gt; P tidymodels * 0.1.2 2020-11-22 [?] CRAN (R 4.0.3) #&gt; tidyr * 1.1.2 2020-08-27 [1] CRAN (R 4.0.3) #&gt; tidyselect 1.1.0 2020-05-11 [1] CRAN (R 4.0.3) #&gt; P timeDate 3043.102 2018-02-21 [?] CRAN (R 4.0.0) #&gt; P tune * 0.1.2 2020-11-17 [?] CRAN (R 4.0.3) #&gt; P utf8 1.1.4 2018-05-24 [?] CRAN (R 4.0.2) #&gt; P vctrs 0.3.6 2020-12-17 [?] CRAN (R 4.0.3) #&gt; P withr 2.4.1 2021-01-26 [?] CRAN (R 4.0.3) #&gt; P workflows * 0.2.1 2020-10-08 [?] CRAN (R 4.0.3) #&gt; P xfun 0.21 2021-02-10 [?] CRAN (R 4.0.2) #&gt; P xml2 1.3.2 2020-04-23 [?] CRAN (R 4.0.2) #&gt; P yaml 2.2.1 2020-02-01 [?] CRAN (R 4.0.0) #&gt; P yardstick * 0.0.7 2020-07-13 [?] CRAN (R 4.0.2) #&gt; #&gt; [1] C:/Users/user/Documents/GitHub/nlp100-knocks-r/renv/library/R-4.0/x86_64-w64-mingw32 #&gt; [2] C:/Users/user/AppData/Local/Temp/RtmpOWulqV/renv-system-library #&gt; #&gt; P -- Loaded and on-disk path mismatch. #&gt; D -- DLL MD5 mismatch, broken installation. "]]
